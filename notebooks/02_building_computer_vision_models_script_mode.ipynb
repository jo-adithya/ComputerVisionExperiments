{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKWDRDDYe2vaZVHZ/W4Tji",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo-adithya/computer-vision-experiments/blob/main/notebooks/02_building_computer_vision_models_script_mode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Computer Vision Models (Script Mode)"
      ],
      "metadata": {
        "id": "szEh-2e--R_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "YkTdr7KU_0qM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup script folder\n",
        "script_path = Path(\"src\")\n",
        "script_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "gHT1mQTA_vth"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create `Dataset`s and `DataLoader`s"
      ],
      "metadata": {
        "id": "cay3enWP-vJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Create script for creating datalaoders"
      ],
      "metadata": {
        "id": "fecYBqNeE3rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for the data_preparation scripts\n",
        "data_preparation_path = script_path / \"data_preparation\"\n",
        "data_preparation_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "fLMnPRPSD74X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/data_preparation/create_dataloaders.py\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoaders.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_path: str,\n",
        "    test_path: str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size: int = 32,\n",
        "    num_workers: int = NUM_WORKERS\n",
        ") -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"Creates training and testing DataLoaders.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_path: str\n",
        "        Path to the training directory.\n",
        "    test_path: str\n",
        "        Path to the testing directory.\n",
        "    train_transform: torchvision.transforms.Compose\n",
        "        torchvision transforms to be performed on the training data.\n",
        "    test_transform: torchvision.transforms.Compose\n",
        "        torchvision transforms to be performed on the testing data.\n",
        "    batch_size: int\n",
        "        Number of samples per batch.\n",
        "    num_workers: int\n",
        "        Number of workers per DataLoader.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A tuple of training dataloader and testing dataloader.\n",
        "    In the form of (train_dataloader, test_dataloader).\n",
        "    \"\"\"\n",
        "    # Create training and testing datasets\n",
        "    train_data = datasets.ImageFolder(train_path, transform=train_transform)\n",
        "    test_data = datasets.ImageFolder(test_path, transform=test_transform)\n",
        "\n",
        "    # Turn datasets into dataloaders\n",
        "    train_dataloader = DataLoader(\n",
        "        dataset=train_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        dataset=test_data,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "\n",
        "__all__ = [\"create_dataloaders\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M48vHezM-vGz",
        "outputId": "e69cc279-ca7b-43d2-fb1f-c381cd0d1a50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/data_preparation/create_dataloaders.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building `PyTorch` models"
      ],
      "metadata": {
        "id": "eILDx7k6-vAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create script for creating `TinyVGG` model"
      ],
      "metadata": {
        "id": "VNZmjHhn-u9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for models script\n",
        "models_path = script_path / \"models\"\n",
        "models_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "q4apV2SF-u7F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/models/tiny_vgg.py\n",
        "\"\"\"\n",
        "Contains PyTorch model class to instantiate a TinyVGG model.\n",
        "\"\"\"\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class TinyVGGConvBlock(nn.Module):\n",
        "    \"\"\"Creates the TinyVGG convolutional block architecture.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels: int\n",
        "        Number of input channels.\n",
        "    out_channels: int\n",
        "        Number of output channels (filters).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=out_channels,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=out_channels,\n",
        "                      out_channels=out_channels,\n",
        "                      kernel_size=3,\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    \"\"\"Creates the TinyVGG model architecture.\n",
        "\n",
        "    Link: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_shape: int\n",
        "        Number of input channels.\n",
        "    hidden_units: int\n",
        "        Number of hidden units between layers.\n",
        "    output_shape: int\n",
        "        Number of output units (number of classes).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape: int,\n",
        "        hidden_units: int,\n",
        "        output_shape: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            TinyVGGConvBlock(in_channels=input_shape, out_channels=hidden_units),\n",
        "            TinyVGGConvBlock(in_channels=hidden_units, out_channels=hidden_units),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(\n",
        "                in_features=13 * 13 * hidden_units,\n",
        "                out_features=output_shape\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.conv_blocks(x))\n",
        "\n",
        "\n",
        "__all__ = [\"TinyVGG\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeSi3cF2-u4e",
        "outputId": "a2924b26-4af1-47ea-dbdd-b76ae862133b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/models/tiny_vgg.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create core training and testing functions"
      ],
      "metadata": {
        "id": "AzTRWPq9-u2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for core function scripts\n",
        "core_path = script_path / \"core\"\n",
        "core_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "397DrWHyQF9M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Create script for the training step function"
      ],
      "metadata": {
        "id": "YQ0Rvr8k-uyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/core/train_step.py\n",
        "\"\"\"\n",
        "Contains functions for core training loop of a PyToch model for one epoch.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def train_step(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    verbose: bool = False,\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"Train a PyTorch model for a single epoch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        A PyTorch model to be trained.\n",
        "    dataloader: DataLoader\n",
        "        A DataLoader to be used for training the model.\n",
        "    loss_fn: nn.Module\n",
        "        A PyTorch loss function to calculate the loss on the training data.\n",
        "    optimizer: torch.optim.Optimizer\n",
        "        A PyTorch optimizer to help minimize the loss function\n",
        "    device: torch.device\n",
        "        Target device to compute on (\"cuda\", \"cpu\", etc.)\n",
        "    verbose: bool\n",
        "        If true, logs the gradients of the model params once after each epoch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form of (train_loss, train_accuracy).\n",
        "    \"\"\"\n",
        "    # Setup the model to be on training mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup training metrics\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "\n",
        "        # Optimize the model params\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the metrics\n",
        "        train_loss += loss.item()\n",
        "        y_pred_classes = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += torch.sum(y_pred_classes == y).item() / len(y_pred)\n",
        "\n",
        "    # Log gradients once per epoch\n",
        "    if verbose:\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                grad_norm = param.grad.norm().item()\n",
        "                print(f\"Layer: {name} | Grad Norm: {grad_norm:.6f}\")\n",
        "            else:\n",
        "                print(f\"Layer: {name} | Grad Norm: None\")\n",
        "        print()\n",
        "\n",
        "    # Calculate the average metrics across all batches\n",
        "    train_loss /= len(dataloader)\n",
        "    train_acc /= len(dataloader)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "__all__ = [\"train_step\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K5mNLod-uv4",
        "outputId": "87c64ba2-088c-47cb-f0ab-65f6a66c775f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/core/train_step.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Create script for the testing step function"
      ],
      "metadata": {
        "id": "ovM6mN_9-uti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/core/test_step.py\n",
        "\"\"\"\n",
        "Contains functions for core testing loop of a PyToch model for one epoch.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def test_step(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    device: torch.device\n",
        ") -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        A PyTorch model to be tested.\n",
        "    dataloader: DataLoader\n",
        "        A DataLoader to be used for testing the model.\n",
        "    loss_fn: nn.Module\n",
        "        A PyTorch loss function to calculate the loss on the testing data.\n",
        "    device: torch.device\n",
        "        Target device to compute on (\"cuda\", \"cpu\", etc.)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form of (test_loss, test_accuracy).\n",
        "    \"\"\"\n",
        "    # Setup the model to be in testing mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup testing metrics\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred = model(X)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = loss_fn(y_pred, y)\n",
        "\n",
        "            # Update the metrics\n",
        "            test_loss += loss.item()\n",
        "            y_pred_classes = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "            test_acc += torch.sum(y_pred_classes == y).item() / len(y_pred)\n",
        "\n",
        "        # Calculate the average metrics across all batches\n",
        "        test_loss /= len(dataloader)\n",
        "        test_acc /= len(dataloader)\n",
        "\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "__all__ = [\"test_step\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv__MY1U-uqr",
        "outputId": "727a41ac-843c-480c-da48-214c45a3a5a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/core/test_step.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Create script for the core training loop function"
      ],
      "metadata": {
        "id": "onSg26fq-uoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/core/train.py\n",
        "\"\"\"\n",
        "Contains functions for core testing loop of a PyToch model.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "from .train_step import train_step\n",
        "from .test_step import test_step\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    train_dataloader: DataLoader,\n",
        "    test_dataloader: DataLoader,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    verbose: bool = False,\n",
        ") -> Dict[str, List[float]]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        A PyTorch model to be trained and tested.\n",
        "    train_dataloader: DataLoader\n",
        "        A DataLoader to be used for training the model.\n",
        "    test_dataloader: DataLoader\n",
        "        A DataLoader to be used for testing the model.\n",
        "    loss_fn: nn.Module\n",
        "        A PyTorch loss function to calculate the loss on both datasets.\n",
        "    optimizer: torch.optim.Optimizer\n",
        "        A PyTorch optimizer to help minimize the loss function\n",
        "    device: torch.device\n",
        "        Target device to compute on (\"cuda\", \"cpu\", etc.)\n",
        "    verbose: bool\n",
        "        If true, logs the gradients of the model params once after each epoch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form:\n",
        "    {\n",
        "        train_loss: [...],\n",
        "        train_acc: [...],\n",
        "        test_loss: [...],\n",
        "        test_acc: [...]\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "    }\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "        print(f\"---------\")\n",
        "\n",
        "        train_loss, train_acc = train_step(\n",
        "            model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            verbose=verbose\n",
        "        )\n",
        "        test_loss, test_acc = test_step(\n",
        "            model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc * 100:.1f}%\")\n",
        "        print(f\"Test loss: {test_loss:.4f} | Test acc: {test_acc * 100:.1f}%\\n\")\n",
        "\n",
        "        # Update the results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "__all__ = [\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM1J2KBM-ulN",
        "outputId": "b64b1212-2425-42c7-ddf9-f7c3b4d00d67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/core/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Create a function to save the model"
      ],
      "metadata": {
        "id": "1FCgrpl--uiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for utils script\n",
        "utils_path = script_path / \"utils\"\n",
        "utils_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "rjRSjw11eR2x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Create script for saving the model"
      ],
      "metadata": {
        "id": "IH9Yu4vQ-ufe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/save_model.py\n",
        "\"\"\"\n",
        "Contains utility function for saving PyTorch model.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def save_model(\n",
        "    model: nn.Module,\n",
        "    target_path: str,\n",
        "    model_name: str,\n",
        "):\n",
        "    \"\"\"Saves a PyTorch model to a target directory.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        A PyTorch model to be saved.\n",
        "    target_path: str\n",
        "        Path for saving the model to.\n",
        "    model_name: str\n",
        "        File name for the saved model.\n",
        "        Should include \".pth\" or \".pt\" file extension.\n",
        "    \"\"\"\n",
        "    # Create the target directory if not exists\n",
        "    target_path = Path(target_path)\n",
        "    target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    assert model_name.endsWith(\".pth\") or model_name.endsWith(\".pt\"),\n",
        "        \"model_name should ends with '.pt' or '.pth'\"\n",
        "    saved_model_path = target_path / model_name\n",
        "\n",
        "    # Save the model\n",
        "    print(f\"[INFO] Saving model to: {saved_model_path}\")\n",
        "    torch.save(obj=model.state_dict(), f=saved_model_path)\n",
        "    print(\"[INFO] Successfully saved the model.\")\n",
        "\n",
        "\n",
        "__all__ = [\"save_model\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuKvdwt6-udI",
        "outputId": "98aa98c4-5d6a-4a28-e33f-59f6df71bf18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/save_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Create utility functions for visualizations"
      ],
      "metadata": {
        "id": "lSix9HGvuKWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for utils script\n",
        "utils_path = script_path / \"utils\"\n",
        "utils_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "c4ibhsa8uSdA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Create script for viewing a batch of the dataloader"
      ],
      "metadata": {
        "id": "s0LP8-RcuTii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/view_dataloader.py\n",
        "\"\"\"\n",
        "Contains functionality for viewing a batch of PyTorch DataLoaders.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def view_dataloader(\n",
        "    dataloader: DataLoader,\n",
        "    ncols: int = 8\n",
        "):\n",
        "    \"\"\"\n",
        "    View a batch of images in the PyTorch DataLoader.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataloader: DataLoader\n",
        "        The dataloader that wants to be viewed.\n",
        "    ncols: int\n",
        "        Number of matplotlib plot columns.\n",
        "    \"\"\"\n",
        "    images, labels = next(iter(dataloader))\n",
        "    nrows = math.ceil(len(images) / ncols)\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(nrows, ncols, i + 1)\n",
        "        plt.imshow(image.permute(1, 2, 0))\n",
        "        plt.set_title(dataloader.classes[labels[i]])\n",
        "        plt.axis(False)\n",
        "\n",
        "\n",
        "__all__ = [\"view_dataloader\"]"
      ],
      "metadata": {
        "id": "-VBqBWO6uTgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e08e04-f61c-4978-a5d0-9a5acd5304be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/view_dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Create script for plotting loss curves"
      ],
      "metadata": {
        "id": "6z7uT266uTcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/plot_loss_curves.py\n",
        "\"\"\"\n",
        "Contains utility function for plotting the model loss curves from the result dictionary.\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "    \"\"\"Plot the model loss curves.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    results: Dict[str, List[float]]\n",
        "        Results dictionary from the training step of a model.\n",
        "        In form of:\n",
        "        {\n",
        "            train_loss: [...],\n",
        "            train_acc: [...],\n",
        "            test_loss: [...],\n",
        "            test_acc: [...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    train_loss = results[\"train_loss\"]\n",
        "    train_acc  = results[\"train_acc\"]\n",
        "    test_loss  = results[\"test_loss\"]\n",
        "    test_acc   = results[\"test_acc\"]\n",
        "\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss,  label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_acc, label=\"train_acc\")\n",
        "    plt.plot(epochs, test_acc,  label=\"test_acc\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "__all__ = [\"plot_loss_curves\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WbSf4oSuTVQ",
        "outputId": "2ee0a7d5-b58e-40be-d85d-67e5e87346f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/plot_loss_curves.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Create script for downloading images from DuckDuckGo"
      ],
      "metadata": {
        "id": "MyQsRj6suTSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path custom testing utils scripts\n",
        "custom_testing_utils_path = utils_path / \"custom_testing\"\n",
        "custom_testing_utils_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "7syfaVdIzK1m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/custom_testing/download_images.py\n",
        "\"\"\"\n",
        "Contains utility function for downloading images from DuckDuckGo.\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def download_images(\n",
        "    target_path: str,\n",
        "    keywords: List[str],\n",
        "    filenames: List[str],\n",
        "    n: int = 1,\n",
        "):\n",
        "    \"\"\"Download images from DuckDuckGo.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    target_path: str\n",
        "        Path for the images to be stored into.\n",
        "    keywords: List[str]\n",
        "        List of image keywords to be searched and dowloaded.\n",
        "    filenames: List[str]\n",
        "        List of filename for the downloaded images.\n",
        "        Just need one filename per keyword.\n",
        "        If n > 1, images will be saved in\n",
        "        filename[0]_0.jpg, filename[0]_1.jpg, filename[1]_0.jpg, etc.\n",
        "    n: int\n",
        "        Number of images to be downloaded for each keyword\n",
        "    \"\"\"\n",
        "    ddg = DDGS()\n",
        "    total_images = len(keywords) * n\n",
        "\n",
        "    # Search for image results\n",
        "    for i, keyword in enumerate(keywords):\n",
        "        results = ddg.images(keyword, max_results=n)\n",
        "\n",
        "        # Download all the images\n",
        "        for j, result in enumerate(results):\n",
        "            while True:\n",
        "                image_url = result[\"image\"]\n",
        "                response = requests.get(image_url)\n",
        "                filename = f\"{filenames[i]}_{j}.jpg\"\n",
        "                target_image_path = target_path / filenames[i]\n",
        "                target_image_path.mkdir(parents=True, exist_ok=True)\n",
        "                if response.status_code == 200:\n",
        "                    image = Image.open(BytesIO(response.content))\n",
        "                    image.save(target_image_path / filename)\n",
        "                    print(f\"Downloaded image {filename}\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Failed to download image {filename}\")\n",
        "\n",
        "\n",
        "__all__ = [\"download_images\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMY2C3yJuTQD",
        "outputId": "a1c37b14-6bb0-48ef-e977-0bda809b3f84"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/custom_testing/download_images.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Create script for reading custom images for testing"
      ],
      "metadata": {
        "id": "8_SROgB8uTN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/custom_testing/read_custom_images.py\n",
        "\"\"\"\n",
        "Contains utility function for reading custom images for testing\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def read_custom_images(image_path: str) -> List[torch.float]:\n",
        "    \"\"\"Read custom images and turn it into PyTorch tensors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_path: str\n",
        "        Path to the custom images that want to be read.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List of PyTorch tensors corresponding to the custom images.\n",
        "    \"\"\"\n",
        "    custom_images_path = Path(image_path).rglob(\"*.*\")\n",
        "    images_arr = []\n",
        "\n",
        "    for i, image_path in enumerate(custom_images_path):\n",
        "        image_arr = torchvision.io.read_image(str(image_path))\n",
        "        normalized_image_arr = image_arr.type(torch.float) / 255.\n",
        "        images_arr.append(normalized_image_arr)\n",
        "\n",
        "    return images_arr\n",
        "\n",
        "\n",
        "__all__ = [\"read_custom_images\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wgesmA_zvyv",
        "outputId": "36325372-eeb4-46f0-b0b1-06976bb2786a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/custom_testing/read_custom_images.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5 Create script for predicting custom images"
      ],
      "metadata": {
        "id": "NO-xzvM7uTL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/custom_testing/predict_images.py\n",
        "\"\"\"\n",
        "Contains utility function for predicting custom images\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from .read_custom_images import read_custom_images\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def predict_images(\n",
        "    model: nn.Module,\n",
        "    image_path: str,\n",
        "    class_names: List[str],\n",
        "    transform: transforms.Compose,\n",
        "    plot_predictions: bool = False,\n",
        "    device: torch.device,\n",
        ") -> List[str]:\n",
        "    \"\"\"Predict custom images.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: nn.Module\n",
        "        A PyTorch model to make the predictions.\n",
        "    image_path: str\n",
        "        Path to the images that wanted to be predicted.\n",
        "    class_names: List[str]\n",
        "        List of class names associated with the model.\n",
        "    transform: transforms.Compose\n",
        "        A transformation function to transform the images into a desired format.\n",
        "    plot_predictions: bool\n",
        "        If true, plot the predictions and the images.\n",
        "    device:\n",
        "        Target device to compute on (\"cuda\", \"cpu\", etc.)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A list of string containing the predicted class names.\n",
        "    \"\"\"\n",
        "    # Load the images\n",
        "    images_arr = read_custom_images(image_path=image_path)\n",
        "\n",
        "    # Transform the images\n",
        "    batch_images = torch.stack([transform(image) for image in images_arr])\n",
        "\n",
        "    # Make the predictions\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        y_pred = model(batch_images.to(device))\n",
        "        pred_probs = torch.softmax(y_pred, dim=1)\n",
        "        pred_labels = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "    predictions = [class_names[label.cpu()] for label in pred_labels]\n",
        "\n",
        "    # Plot the predictions\n",
        "    if plot_predictions:\n",
        "        import matplotlib.pyplot as plt\n",
        "        ncols = 2\n",
        "        nrows = math.ceil(len(images_arr) / ncols)\n",
        "        for i, image in enumerate(images_arr):\n",
        "            plt.subplot(nrows, ncols, i + 1)\n",
        "            plt.imshow(image.permute(1, 2, 0))\n",
        "            plt.title(f\"{predictions[i]} ({pred_probs[i].max().cpu() * 100:.1f}%)\")\n",
        "            plt.axis(False)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "__all__ = [\"predict_images\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L52HqamRuTIP",
        "outputId": "7947f702-e749-46e6-dc64-3c364c1fed50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/custom_testing/predict_images.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PjiNUETIuTF5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Create `__init__.py` files for easier imports"
      ],
      "metadata": {
        "id": "Rb-YQAOO-uaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/core/__init__.py\n",
        "from .train import train\n",
        "\n",
        "__all__ = [\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GThNQ92B-uXq",
        "outputId": "b1905fd7-46f4-4914-b3f6-cd70c25ae718"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/core/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/data_preparation/__init__.py\n",
        "from .create_dataloaders import create_dataloaders\n",
        "\n",
        "__all__ = [\"create_dataloaders\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd4qOy6--uVD",
        "outputId": "9dd42f6e-59cf-4a0c-8e93-e629b249e984"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/data_preparation/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/models/__init__.py\n",
        "from .tiny_vgg import TinyVGG\n",
        "\n",
        "__all__ = [\"TinyVGG\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJvy3R_T-uSt",
        "outputId": "6a1edd67-be54-458c-f905-fb4b303223e4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/models/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/__init__.py\n",
        "from .plot_loss_curves import plot_loss_curves\n",
        "from .save_model import save_model\n",
        "from .view_dataloader import view_dataloader\n",
        "\n",
        "__all__ = [\n",
        "    \"plot_loss_curves\",\n",
        "    \"save_model\",\n",
        "    \"view_dataloader\",\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS0lWX1M-uOB",
        "outputId": "920a1656-fe90-40d8-a3b3-d203729a0f10"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/custom_testing/__init__.py\n",
        "from .download_images import download_images\n",
        "from .predict_images import predict_images\n",
        "\n",
        "__all__ = [\n",
        "    \"download_images\",\n",
        "    \"predict_images\",\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m_qhliJi8k3",
        "outputId": "bb799054-215d-4615-9867-0b6b3d148c80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/custom_testing/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLGvVVpY5pBr"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}